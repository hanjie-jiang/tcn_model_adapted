{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e33d78",
   "metadata": {},
   "source": [
    "### adapted from locuslab/TCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe58b28",
   "metadata": {},
   "source": [
    "#### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8530c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import csv\n",
    "import re\n",
    "from matplotlib import cm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30da8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9cf9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from filelock import FileLock\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd9c88",
   "metadata": {},
   "source": [
    "#### data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15bfae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(path, pattern_interest): \n",
    "    # reading in the data\n",
    "    data = pd.read_csv(path,header=0)\n",
    "    # sorting data in dataframe\n",
    "    df1 = pd.DataFrame(data)\n",
    "    \n",
    "    #getting only the step 11 related variables\n",
    "    step11vars = [col for col in df1.columns if col.split('.')[0] == '11']\n",
    "    df2 = df1.loc[:, df1.columns.isin(step11vars)]\n",
    "    \n",
    "    # getting only the faceplate, bottom heater and heater outerzone related variables within the step11 dataset\n",
    "\n",
    "    # bottom heater related\n",
    "    bottom_related = [col for col in df2.columns if 'Bottom' in col]\n",
    "    dfb = df2.loc[:, df2.columns.isin(bottom_related)]\n",
    "\n",
    "    # faceplate related\n",
    "    faceplate_related = [col for col in df2.columns if \"Faceplate\" in col]\n",
    "    dff = df2.loc[:, df2.columns.isin(faceplate_related)]\n",
    "\n",
    "    # heater outer-zone related\n",
    "    outer_related = [col for col in df2.columns if \"HeaterOuter\" in col]\n",
    "    dfo = df2.loc[:, df2.columns.isin(outer_related)]\n",
    "    \n",
    "    # heater exchanger related\n",
    "    hx_related = [col for col in df2.columns if \"HX\" in col]\n",
    "    dfx = df2.loc[:, df2.columns.isin(hx_related)]\n",
    "    \n",
    "    # heater exchanger related\n",
    "    inner_related = [col for col in df2.columns if \"HeaterInner\" in col]\n",
    "    dfi = df2.loc[:, df2.columns.isin(inner_related)]\n",
    "    \n",
    "    # merge the three keywords related datasets together into `dfall`\n",
    "    dfall = pd.concat([dfb, dff, dfo, dfx, dfi], axis=1)\n",
    "    \n",
    "    mean_related = [col for col in dfall.columns if \"mean\" in col]\n",
    "    dfmean = dfall.loc[:, dfall.columns.isin(mean_related)]\n",
    "    \n",
    "    #Xbotmean = dfmean[dfmean.columns.drop(list(dfmean.filter(regex='11.FaceplateHeater_Temperature.mean')))]\n",
    "    Xmean = dfmean[dfmean.columns.drop(list(dfmean.filter(regex=pattern_interest)))]\n",
    "    ymean = dfmean.loc[:,[pattern_interest]]\n",
    "    \n",
    "    return Xmean, ymean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af038f",
   "metadata": {},
   "source": [
    "#### TCN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8719558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0719b979",
   "metadata": {},
   "source": [
    "#### upper level of the TCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c579251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
    "        super(TCN, self).__init__()\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "        self.init_weights() # if the data needs to be weighted\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.linear.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.tcn(x)  # if multidimensional, input should have dimension (N, C, L)\n",
    "        o = self.linear(y1[:, :, -1])\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a91209",
   "metadata": {},
   "source": [
    "#### data generator for the adding problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45409e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def data_generator(percent_train, seq_length, path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        seq_length: Length of the adding problem data\n",
    "        starting_index: the index of where the sequence starts; starting from 0\n",
    "    \"\"\"\n",
    "    # Specifying the feature columns that we need for predictions\n",
    "    col1 = '11.BottomHeater_Temperature.mean'\n",
    "    col2 = '11.FaceplateHeater_Temperature.mean'\n",
    "    col3 = '11.HeaterOuterZone_Temperature.mean'\n",
    "    col = [col1, col2, col3]\n",
    "    \n",
    "    # Giving the path to the data set\n",
    "    csv = path\n",
    "    \n",
    "    # Data cleaning, getting the feature matrix and \n",
    "    X_bot, y_bot = data_cleaning(csv, col2)\n",
    "    \n",
    "    X_bot = torch.tensor(X_bot.to_numpy()).float()\n",
    "    y_bot = torch.tensor(y_bot.to_numpy()).float()\n",
    "    print(\"converted X_bot \", X_bot.shape, \"and y_bot \", y_bot.shape, \" to tensors\\n\")\n",
    "    \n",
    "    X_bot1 = torch.reshape(X_bot, [1, X_bot.shape[1], X_bot.shape[0]]) #[1,14,274]\n",
    "    y_bot1 = torch.reshape(y_bot, [1, y_bot.shape[0]]) #[1,274]\n",
    "\n",
    "    first_test_idx = int(round(percent_train * X_bot.shape[0]))\n",
    "    X_train = X_bot1[:, :, 0:first_test_idx]\n",
    "    X_test = X_bot1[:, :, first_test_idx:]\n",
    "    y_train = y_bot1[:, 0:first_test_idx]\n",
    "    y_test = y_bot1[:, first_test_idx:]\n",
    "    \n",
    "    X_train_final = torch.zeros([X_train.shape[2]-seq_length, X_train.shape[1], seq_length]) #[196, 14, 10] = [206-10, 14, 10]\n",
    "    y_train_final = torch.zeros([y_train.shape[1]-seq_length, 1]) #[196, 1] = [206-10, 1]\n",
    "    X_test_final = torch.zeros([X_test.shape[2]-seq_length, X_test.shape[1], seq_length]) #[58, 14, 10] = [68-10, 14, 10]\n",
    "    y_test_final = torch.zeros([y_test.shape[1]-seq_length, 1]) #[58,1] = [68-10, 1]\n",
    "    \n",
    "    for i in range(X_train.shape[2]-seq_length):\n",
    "        X_train_final[i, :, :] = X_train[: , : , i:i+seq_length]\n",
    "        y_train_final[i, :] = y_train[: , i+seq_length:i+seq_length+1]\n",
    "        \n",
    "    for i in range(X_test.shape[2]-seq_length):\n",
    "        X_test_final[i, :, :] = X_test[: , : , i:i+seq_length]\n",
    "        y_test_final[i, :] = y_test[: , i+seq_length:i+seq_length+1]\n",
    "#         print(\"at index i = \", i, \"y_test[1, \", i+seq_length, \"] = \",y_test[: , i+seq_length:i+seq_length+1])\n",
    "#         print(\"at index i = \", i, \"y_test_final[\",i, \", :] = \", y_test_final[i, :])\n",
    "\n",
    "    \n",
    "#     print(\"Y_train shape is set to: \", y_train_final.shape, \"; Y_train type is: \", type(y_train_final), \"\\n\")\n",
    "#     print(\"X_train shape is set to: \", X_train_final.shape, \"; X_train type is: \", type(X_train_final), \"\\n\")\n",
    "#     print(\"Y_test shape is set to: \", y_test_final.shape, \"; Y_test type is: \", type(y_test_final), \"\\n\")\n",
    "#     print(\"X_test shape is set to: \", X_test_final.shape, \"; X_test type is: \", type(X_test_final), \"\\n\")    \n",
    "    \n",
    "    return Variable(X_train_final), Variable(y_train_final), Variable(X_test_final), Variable(y_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d987e44",
   "metadata": {},
   "source": [
    "#### parameters needed for the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "715f4970",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 14 # # of input features\n",
    "n_classes = 1  #size of each output sample; output feature sizes of y_pred\n",
    "batch_size = 16 #batch size defaults to 32\n",
    "seq_length = 5 #sequence length; defaults to 400\n",
    "epochs = 10 #upper epoch limit; defaults to 10\n",
    "clip = -1 #args.clip; gradient clip, -1 means no clip (default: -1)\n",
    "log_interval = 5 #args.log_interval; 'report interval (default: 100')\n",
    "channel_sizes = [70]*2 #[args.nhid]*args.levels; number of hidden units per layer * # of levels\n",
    "kernel_size = 5 #args.ksize; kernel_size\n",
    "dropout =  0.0 #args.dropout; dropouts applied to each layer; defaults to 0.0\n",
    "model = TCN(input_channels, n_classes, channel_sizes, kernel_size=kernel_size, dropout=dropout)\n",
    "lr = 0.0027257365073673117 # learning rate is defaulted to be 0.0040\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) #optimizer = getattr(optim, args.optim)(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa65da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted X_bot  torch.Size([274, 14]) and y_bot  torch.Size([274, 1])  to tensors\n",
      "\n",
      "torch.Size([214, 14, 5]) torch.Size([214, 1]) torch.Size([50, 14, 5]) torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "percent = 0.8\n",
    "X_train, Y_train, X_test, Y_test = data_generator(percent, seq_length, r\"C:\\Users\\e177321\\Documents\\data\\Marathon_data.csv\")\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e784c8c3",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce8873bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, input_channels=14):\n",
    "    global lr\n",
    "    \n",
    "    model.train()\n",
    "    batch_idx = 1\n",
    "    total_loss = 0\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        if i + batch_size > X_train.size(0):\n",
    "            x, y = X_train[i:], Y_train[i:]\n",
    "        else:\n",
    "            x, y = X_train[i:(i+batch_size)], Y_train[i:(i+batch_size)]\n",
    "            \n",
    "        #print(\"x.shape = \", x.shape, \"y.shape = \", y.shape)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = torch.nn.functional.mse_loss(output, y)\n",
    "        loss.backward()\n",
    "        if clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        batch_idx += 1\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            processed = min(i+batch_size, X_train.size(0))\n",
    "            print('Train Epoch: {:2d} [{:6d}/{:6d} ({:.0f}%)]\\tLearning rate: {:.4f}\\tLoss: {:.6f}'.format(\n",
    "                epoch, processed, X_train.size(0), 100.*processed/X_train.size(0), lr, cur_loss))\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e5073",
   "metadata": {},
   "source": [
    "#### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ae7c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test)\n",
    "        test_loss = torch.nn.functional.mse_loss(output, Y_test)\n",
    "        print('\\nTest set: Average loss: {:.6f}\\n'.format(test_loss.item()))\n",
    "        return Y_test, output, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f24f572d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  1 [    64/   214 (30%)]\tLearning rate: 0.0027\tLoss: 31962.910547\n",
      "Train Epoch:  1 [   144/   214 (67%)]\tLearning rate: 0.0027\tLoss: 7467.189941\n",
      "Train Epoch:  1 [   214/   214 (100%)]\tLearning rate: 0.0027\tLoss: 5330.549512\n",
      "\n",
      "Test set: Average loss: 1274.683350\n",
      "\n",
      "Train Epoch:  2 [    64/   214 (30%)]\tLearning rate: 0.0027\tLoss: 769.165460\n",
      "Train Epoch:  2 [   144/   214 (67%)]\tLearning rate: 0.0027\tLoss: 1395.344113\n",
      "Train Epoch:  2 [   214/   214 (100%)]\tLearning rate: 0.0027\tLoss: 946.072327\n",
      "\n",
      "Test set: Average loss: 461.647430\n",
      "\n",
      "Train Epoch:  3 [    64/   214 (30%)]\tLearning rate: 0.0027\tLoss: 178.327058\n",
      "Train Epoch:  3 [   144/   214 (67%)]\tLearning rate: 0.0027\tLoss: 328.757624\n",
      "Train Epoch:  3 [   214/   214 (100%)]\tLearning rate: 0.0027\tLoss: 166.839700\n",
      "\n",
      "Test set: Average loss: 87.367996\n",
      "\n",
      "Train Epoch:  4 [    64/   214 (30%)]\tLearning rate: 0.0027\tLoss: 34.152102\n",
      "Train Epoch:  4 [   144/   214 (67%)]\tLearning rate: 0.0027\tLoss: 71.006467\n",
      "Train Epoch:  4 [   214/   214 (100%)]\tLearning rate: 0.0027\tLoss: 43.044210\n",
      "\n",
      "Test set: Average loss: 13.834460\n",
      "\n",
      "Train Epoch:  5 [    64/   214 (30%)]\tLearning rate: 0.0027\tLoss: 10.292655\n",
      "Train Epoch:  5 [   144/   214 (67%)]\tLearning rate: 0.0027\tLoss: 14.579362\n",
      "Train Epoch:  5 [   214/   214 (100%)]\tLearning rate: 0.0027\tLoss: 11.069036\n",
      "\n",
      "Test set: Average loss: 0.914138\n",
      "\n",
      "Train Epoch:  6 [    64/   214 (30%)]\tLearning rate: 0.0027\tLoss: 4.051750\n",
      "Train Epoch:  6 [   144/   214 (67%)]\tLearning rate: 0.0027\tLoss: 2.527702\n",
      "Train Epoch:  6 [   214/   214 (100%)]\tLearning rate: 0.0027\tLoss: 2.140189\n",
      "\n",
      "Test set: Average loss: 1.890810\n",
      "\n",
      "Train Epoch:  7 [    64/   214 (30%)]\tLearning rate: 0.0027\tLoss: 1.202493\n",
      "Train Epoch:  7 [   144/   214 (67%)]\tLearning rate: 0.0027\tLoss: 0.693202\n",
      "Train Epoch:  7 [   214/   214 (100%)]\tLearning rate: 0.0027\tLoss: 0.349355\n",
      "\n",
      "Test set: Average loss: 0.348549\n",
      "\n",
      "Train Epoch:  8 [    64/   214 (30%)]\tLearning rate: 0.0027\tLoss: 0.132611\n",
      "Train Epoch:  8 [   144/   214 (67%)]\tLearning rate: 0.0027\tLoss: 0.186004\n",
      "Train Epoch:  8 [   214/   214 (100%)]\tLearning rate: 0.0027\tLoss: 0.102665\n",
      "\n",
      "Test set: Average loss: 0.084856\n",
      "\n",
      "Train Epoch:  9 [    64/   214 (30%)]\tLearning rate: 0.0027\tLoss: 0.070628\n",
      "Train Epoch:  9 [   144/   214 (67%)]\tLearning rate: 0.0027\tLoss: 0.047133\n",
      "Train Epoch:  9 [   214/   214 (100%)]\tLearning rate: 0.0027\tLoss: 0.029898\n",
      "\n",
      "Test set: Average loss: 0.017215\n",
      "\n",
      "Train Epoch: 10 [    64/   214 (30%)]\tLearning rate: 0.0027\tLoss: 0.023062\n",
      "Train Epoch: 10 [   144/   214 (67%)]\tLearning rate: 0.0027\tLoss: 0.015863\n",
      "Train Epoch: 10 [   214/   214 (100%)]\tLearning rate: 0.0027\tLoss: 0.011469\n",
      "\n",
      "Test set: Average loss: 0.025666\n",
      "\n",
      "min loss found in ep  9  with minloss equals: 0.01721453107893467 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = []\n",
    "lstoutput = []\n",
    "lstytest = []\n",
    "for ep in range(1, epochs+1):\n",
    "    train(ep)\n",
    "    Y_test, output, test_loss = evaluate()  \n",
    "    loss.append(test_loss.item())\n",
    "    lstoutput.append(output.tolist())\n",
    "    lstytest.append(Y_test.tolist())\n",
    "    \n",
    "minloss = min(loss)\n",
    "minidx = loss.index(minloss)\n",
    "\n",
    "Y_test = lstytest[minidx]\n",
    "output = lstoutput[minidx]\n",
    "    \n",
    "f, ax = plt.subplots()\n",
    "print(\"min loss found in ep \", minidx+1, \" with minloss equals:\", minloss, \"\\n\")\n",
    "ax.scatter(Y_test, output,  color='black')\n",
    "ax.set_xlabel('Outputs from Marathon data')\n",
    "ax.set_ylabel('Outputs from predictions')\n",
    "plt.xlim(250.50, 251.0)\n",
    "plt.ylim(250.50, 251.0)\n",
    "figname = \"faceplate_tcn_opt\"\n",
    "ax.figure.savefig(figname, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b65c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
