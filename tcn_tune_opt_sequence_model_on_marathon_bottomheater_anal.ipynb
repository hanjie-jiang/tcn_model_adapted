{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e33d78",
   "metadata": {},
   "source": [
    "### adapted from locuslab/TCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe58b28",
   "metadata": {},
   "source": [
    "#### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8530c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import csv\n",
    "import re\n",
    "from matplotlib import cm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30da8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9cf9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from filelock import FileLock\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd9c88",
   "metadata": {},
   "source": [
    "#### data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15bfae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(path, pattern_interest): \n",
    "    # reading in the data\n",
    "    data = pd.read_csv(path,header=0)\n",
    "    # sorting data in dataframe\n",
    "    df1 = pd.DataFrame(data)\n",
    "    \n",
    "    #getting only the step 11 related variables\n",
    "    step11vars = [col for col in df1.columns if col.split('.')[0] == '11']\n",
    "    df2 = df1.loc[:, df1.columns.isin(step11vars)]\n",
    "    \n",
    "    # getting only the faceplate, bottom heater and heater outerzone related variables within the step11 dataset\n",
    "\n",
    "    # bottom heater related\n",
    "    bottom_related = [col for col in df2.columns if 'Bottom' in col]\n",
    "    dfb = df2.loc[:, df2.columns.isin(bottom_related)]\n",
    "\n",
    "    # faceplate related\n",
    "    faceplate_related = [col for col in df2.columns if \"Faceplate\" in col]\n",
    "    dff = df2.loc[:, df2.columns.isin(faceplate_related)]\n",
    "\n",
    "    # heater outer-zone related\n",
    "    outer_related = [col for col in df2.columns if \"HeaterOuter\" in col]\n",
    "    dfo = df2.loc[:, df2.columns.isin(outer_related)]\n",
    "    \n",
    "    # heater exchanger related\n",
    "    hx_related = [col for col in df2.columns if \"HX\" in col]\n",
    "    dfx = df2.loc[:, df2.columns.isin(hx_related)]\n",
    "    \n",
    "    # heater exchanger related\n",
    "    inner_related = [col for col in df2.columns if \"HeaterInner\" in col]\n",
    "    dfi = df2.loc[:, df2.columns.isin(inner_related)]\n",
    "    \n",
    "    # merge the three keywords related datasets together into `dfall`\n",
    "    dfall = pd.concat([dfb, dff, dfo, dfx, dfi], axis=1)\n",
    "    \n",
    "    mean_related = [col for col in dfall.columns if \"mean\" in col]\n",
    "    dfmean = dfall.loc[:, dfall.columns.isin(mean_related)]\n",
    "    \n",
    "    #Xbotmean = dfmean[dfmean.columns.drop(list(dfmean.filter(regex='11.FaceplateHeater_Temperature.mean')))]\n",
    "    Xmean = dfmean[dfmean.columns.drop(list(dfmean.filter(regex=pattern_interest)))]\n",
    "    ymean = dfmean.loc[:,[pattern_interest]]\n",
    "    \n",
    "    return Xmean, ymean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af038f",
   "metadata": {},
   "source": [
    "#### TCN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8719558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0719b979",
   "metadata": {},
   "source": [
    "#### upper level of the TCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c579251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
    "        super(TCN, self).__init__()\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "        self.init_weights() # if the data needs to be weighted\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.linear.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.tcn(x)  # if multidimensional, input should have dimension (N, C, L)\n",
    "        o = self.linear(y1[:, :, -1])\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a91209",
   "metadata": {},
   "source": [
    "#### data generator for the adding problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45409e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def data_generator(percent_train, seq_length, path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        seq_length: Length of the adding problem data\n",
    "        starting_index: the index of where the sequence starts; starting from 0\n",
    "    \"\"\"\n",
    "    # Specifying the feature columns that we need for predictions\n",
    "    col1 = '11.BottomHeater_Temperature.mean'\n",
    "    col2 = '11.FaceplateHeater_Temperature.mean'\n",
    "    col3 = '11.HeaterOuterZone_Temperature.mean'\n",
    "    col = [col1, col2, col3]\n",
    "    \n",
    "    # Giving the path to the data set\n",
    "    csv = path\n",
    "    \n",
    "    # Data cleaning, getting the feature matrix and \n",
    "    X_bot, y_bot = data_cleaning(csv, col1)\n",
    "    \n",
    "    X_bot = torch.tensor(X_bot.to_numpy()).float()\n",
    "    y_bot = torch.tensor(y_bot.to_numpy()).float()\n",
    "    print(\"converted X_bot \", X_bot.shape, \"and y_bot \", y_bot.shape, \" to tensors\\n\")\n",
    "    \n",
    "    X_bot1 = torch.reshape(X_bot, [1, X_bot.shape[1], X_bot.shape[0]]) #[1,14,274]\n",
    "    y_bot1 = torch.reshape(y_bot, [1, y_bot.shape[0]]) #[1,274]\n",
    "\n",
    "    first_test_idx = int(round(percent_train * X_bot.shape[0]))\n",
    "    X_train = X_bot1[:, :, 0:first_test_idx]\n",
    "    X_test = X_bot1[:, :, first_test_idx:]\n",
    "    y_train = y_bot1[:, 0:first_test_idx]\n",
    "    y_test = y_bot1[:, first_test_idx:]\n",
    "    \n",
    "    X_train_final = torch.zeros([X_train.shape[2]-seq_length, X_train.shape[1], seq_length]) #[196, 14, 10] = [206-10, 14, 10]\n",
    "    y_train_final = torch.zeros([y_train.shape[1]-seq_length, 1]) #[196, 1] = [206-10, 1]\n",
    "    X_test_final = torch.zeros([X_test.shape[2]-seq_length, X_test.shape[1], seq_length]) #[58, 14, 10] = [68-10, 14, 10]\n",
    "    y_test_final = torch.zeros([y_test.shape[1]-seq_length, 1]) #[58,1] = [68-10, 1]\n",
    "    \n",
    "    for i in range(X_train.shape[2]-seq_length):\n",
    "        X_train_final[i, :, :] = X_train[: , : , i:i+seq_length]\n",
    "        y_train_final[i, :] = y_train[: , i+seq_length:i+seq_length+1]\n",
    "        \n",
    "    for i in range(X_test.shape[2]-seq_length):\n",
    "        X_test_final[i, :, :] = X_test[: , : , i:i+seq_length]\n",
    "        y_test_final[i, :] = y_test[: , i+seq_length:i+seq_length+1]\n",
    "#         print(\"at index i = \", i, \"y_test[1, \", i+seq_length, \"] = \",y_test[: , i+seq_length:i+seq_length+1])\n",
    "#         print(\"at index i = \", i, \"y_test_final[\",i, \", :] = \", y_test_final[i, :])\n",
    "\n",
    "    \n",
    "#     print(\"Y_train shape is set to: \", y_train_final.shape, \"; Y_train type is: \", type(y_train_final), \"\\n\")\n",
    "#     print(\"X_train shape is set to: \", X_train_final.shape, \"; X_train type is: \", type(X_train_final), \"\\n\")\n",
    "#     print(\"Y_test shape is set to: \", y_test_final.shape, \"; Y_test type is: \", type(y_test_final), \"\\n\")\n",
    "#     print(\"X_test shape is set to: \", X_test_final.shape, \"; X_test type is: \", type(X_test_final), \"\\n\")    \n",
    "    \n",
    "    return Variable(X_train_final), Variable(y_train_final), Variable(X_test_final), Variable(y_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d987e44",
   "metadata": {},
   "source": [
    "#### parameters needed for the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "715f4970",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 14 # # of input features\n",
    "n_classes = 1  #size of each output sample; output feature sizes of y_pred\n",
    "batch_size = 16 #batch size defaults to 32\n",
    "seq_length = 5 #sequence length; defaults to 400\n",
    "epochs = 10 #upper epoch limit; defaults to 10\n",
    "clip = -1 #args.clip; gradient clip, -1 means no clip (default: -1)\n",
    "log_interval = 100 #args.log_interval; 'report interval (default: 100')\n",
    "channel_sizes = [70]*2 #[args.nhid]*args.levels; number of hidden units per layer * # of levels\n",
    "kernel_size = 5 #args.ksize; kernel_size\n",
    "dropout =  0.0 #args.dropout; dropouts applied to each layer; defaults to 0.0\n",
    "model = TCN(input_channels, n_classes, channel_sizes, kernel_size=kernel_size, dropout=dropout)\n",
    "lr = 0.0027257365073673117 # learning rate is defaulted to be 0.0040\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) #optimizer = getattr(optim, args.optim)(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa65da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted X_bot  torch.Size([274, 14]) and y_bot  torch.Size([274, 1])  to tensors\n",
      "\n",
      "torch.Size([214, 14, 5]) torch.Size([214, 1]) torch.Size([50, 14, 5]) torch.Size([50, 1])\n"
     ]
    }
   ],
   "source": [
    "percent = 0.8\n",
    "X_train, Y_train, X_test, Y_test = data_generator(percent, seq_length, r\"C:\\Users\\e177321\\Documents\\data\\Marathon_data.csv\")\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17c7795a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e784c8c3",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce8873bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, input_channels=14):\n",
    "    global lr\n",
    "    \n",
    "    model.train()\n",
    "    batch_idx = 1\n",
    "    total_loss = 0\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        if i + batch_size > X_train.size(0):\n",
    "            x, y = X_train[i:], Y_train[i:]\n",
    "        else:\n",
    "            x, y = X_train[i:(i+batch_size)], Y_train[i:(i+batch_size)]\n",
    "            \n",
    "        #print(\"x.shape = \", x.shape, \"y.shape = \", y.shape)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = torch.nn.functional.mse_loss(output, y)\n",
    "        loss.backward()\n",
    "        if clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        batch_idx += 1\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            processed = min(i+batch_size, X_train.size(0))\n",
    "            print('Train Epoch: {:2d} [{:6d}/{:6d} ({:.0f}%)]\\tLearning rate: {:.4f}\\tLoss: {:.6f}'.format(\n",
    "                epoch, processed, X_train.size(0), 100.*processed/X_train.size(0), lr, cur_loss))\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e5073",
   "metadata": {},
   "source": [
    "#### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55ae7c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test)\n",
    "        test_loss = torch.nn.functional.mse_loss(output, Y_test)\n",
    "        print('\\nTest set: Average loss: {:.6f}\\n'.format(test_loss.item()))\n",
    "        return Y_test, output, test_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a2c9fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f24f572d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 837.386414\n",
      "\n",
      "\n",
      "Test set: Average loss: 17.486008\n",
      "\n",
      "\n",
      "Test set: Average loss: 39.842075\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.321211\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.679870\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.067076\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.042416\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.115663\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.014595\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.018467\n",
      "\n",
      "min loss found in ep  8 : minloss =  0.014594539068639278 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = []\n",
    "lstoutput = []\n",
    "lstytest = []\n",
    "for ep in range(1, epochs+1):\n",
    "    train(ep)\n",
    "    ytest, output, test_loss = evaluate()  \n",
    "    loss.append(test_loss)\n",
    "    lstoutput.append(output.tolist())\n",
    "    lstytest.append(ytest.tolist())\n",
    "\n",
    "    minloss = min(loss)\n",
    "    minidx = loss.index(minloss)\n",
    "\n",
    "    ytest = lstytest[minidx]\n",
    "    output = lstoutput[minidx]\n",
    "\n",
    "print(\"min loss found in ep \", minidx, \": minloss = \", minloss, \"\\n\")\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.scatter(ytest, output,  color='black')\n",
    "ax.set_xlabel('Outputs from Marathon data')\n",
    "ax.set_ylabel('Outputs from predictions')\n",
    "\n",
    "plt.xlim(159.7,160.20)\n",
    "plt.ylim(159.7,160.20)\n",
    "#plt.gca().set_aspect('equal', adjustable='box')\n",
    "figname = \"bottom_tcn_opt\"\n",
    "ax.figure.savefig(figname, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f229a",
   "metadata": {},
   "source": [
    "**seq_length = 3:** min loss found in ep  7 : minloss =  0.046425484120845795 <br>\n",
    "**seq_length = 5:** min loss found in ep  6 : minloss =  0.03591875731945038  <br>\n",
    "**seq_length = 6:** min loss found in ep  6 : minloss =  0.0220029279589653   <br>\n",
    "**seq_length = 7:** min loss found in ep  8 : minloss =  0.024872690439224243 <br>\n",
    "**seq_length = 8:** min loss found in ep  8 : minloss =  0.0209933053702116   <br>\n",
    "**seq_length = 9** min loss found in ep  9 : minloss =  0.022520944476127625   <br>\n",
    "**seq_length = 10:** min loss found in ep  9 : minloss =  0.0950486958026886  <br>\n",
    "**seq_length = 12:** min loss found in ep  9 : minloss =  0.20230647921562195  <br>\n",
    "**seq_length = 15:** min loss found in ep  9 : minloss =  0.03576983883976936  <br>\n",
    "**seq_length = 20**min loss found in ep  8 : minloss =  0.11364954710006714  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6bcc765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def evaluate():\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         output = model(X_test)\n",
    "#         test_loss = torch.nn.functional.mse_loss(output, Y_test)\n",
    "#         print('\\nTest set: Average loss: {:.6f}\\n'.format(test_loss.item()))\n",
    "#         return test_loss\n",
    "\n",
    "# #loss = []\n",
    "\n",
    "# eploss = []\n",
    "\n",
    "# for i in [5, 10, 12, 15, 18, 20, 25, 30]:\n",
    "#     loss = []\n",
    "#     epochs = i\n",
    "#     for ep in range(1, epochs+1):\n",
    "#         train(ep)\n",
    "#         test_loss = evaluate()  \n",
    "#         loss.append(test_loss.item())\n",
    "\n",
    "#         minloss = min(loss)\n",
    "#         minidx = loss.index(minloss)\n",
    "        \n",
    "#     print(\"when epoch = \", i, \" minloss = \", minloss, \"\\n\")\n",
    "#     eploss.append([i, minloss])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba78e51",
   "metadata": {},
   "source": [
    "when epoch =  5  minloss =  1.8050010204315186 <br>\n",
    "when epoch =  10  minloss =  0.02135978452861309 <br>\n",
    "when epoch =  12  minloss =  0.013690745458006859 <br>\n",
    "when epoch =  15  minloss =  0.013690745458006859<br>\n",
    "when epoch =  20  minloss =  0.013690745458006859 <br>\n",
    "when epoch =  25  minloss =  0.012305893003940582 <br>\n",
    "when epoch =  30  minloss =  0.012305893003940582 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a94e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eploss = np.array(eploss)\n",
    "# figep, axep = plt.subplots()\n",
    "# plt.plot(eploss[:,0],eploss[:,1])\n",
    "# plt.scatter(eploss[:,0],eploss[:,1])\n",
    "# axep.figure.savefig(\"ep_effect.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71579943",
   "metadata": {},
   "source": [
    "**seq_length = 3:** min loss found in ep  7 : minloss =  0.046425484120845795 <br>\n",
    "**seq_length = 5:** min loss found in ep  6 : minloss =  0.03591875731945038  <br>\n",
    "**seq_length = 6:** min loss found in ep  6 : minloss =  0.0220029279589653   <br>\n",
    "**seq_length = 7:** min loss found in ep  8 : minloss =  0.024872690439224243 <br>\n",
    "**seq_length = 8:** min loss found in ep  8 : minloss =  0.0209933053702116   <br>\n",
    "**seq_length = 9** min loss found in ep  9 : minloss =  0.022520944476127625   <br>\n",
    "**seq_length = 10:** min loss found in ep  9 : minloss =  0.0950486958026886  <br>\n",
    "**seq_length = 12:** min loss found in ep  9 : minloss =  0.20230647921562195  <br>\n",
    "**seq_length = 15:** min loss found in ep  9 : minloss =  0.03576983883976936  <br>\n",
    "**seq_length = 20**min loss found in ep  8 : minloss =  0.11364954710006714  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e51d2f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seqloss = np.array(losscomp)\n",
    "# figseq, axseq = plt.subplots()\n",
    "# axseq.plot(seqloss[:,0], seqloss[:, 1])\n",
    "# axseq.scatter(seqloss[:,0], seqloss[:, 1])\n",
    "# axseq.figure.savefig(\"seq_length_effect\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3859c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = min(seqloss[:,1])\n",
    "# print(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c14db4df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# losscomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fec756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
