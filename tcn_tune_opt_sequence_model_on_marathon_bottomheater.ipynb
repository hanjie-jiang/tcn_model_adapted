{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e33d78",
   "metadata": {},
   "source": [
    "### adapted from locuslab/TCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe58b28",
   "metadata": {},
   "source": [
    "#### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8530c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import csv\n",
    "import re\n",
    "from matplotlib import cm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30da8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9cf9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from filelock import FileLock\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd9c88",
   "metadata": {},
   "source": [
    "#### data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15bfae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(path, pattern_interest): \n",
    "    # reading in the data\n",
    "    data = pd.read_csv(path,header=0)\n",
    "    # sorting data in dataframe\n",
    "    df1 = pd.DataFrame(data)\n",
    "    \n",
    "    #getting only the step 11 related variables\n",
    "    step11vars = [col for col in df1.columns if col.split('.')[0] == '11']\n",
    "    df2 = df1.loc[:, df1.columns.isin(step11vars)]\n",
    "    \n",
    "    # getting only the faceplate, bottom heater and heater outerzone related variables within the step11 dataset\n",
    "\n",
    "    # bottom heater related\n",
    "    bottom_related = [col for col in df2.columns if 'Bottom' in col]\n",
    "    dfb = df2.loc[:, df2.columns.isin(bottom_related)]\n",
    "\n",
    "    # faceplate related\n",
    "    faceplate_related = [col for col in df2.columns if \"Faceplate\" in col]\n",
    "    dff = df2.loc[:, df2.columns.isin(faceplate_related)]\n",
    "\n",
    "    # heater outer-zone related\n",
    "    outer_related = [col for col in df2.columns if \"HeaterOuter\" in col]\n",
    "    dfo = df2.loc[:, df2.columns.isin(outer_related)]\n",
    "    \n",
    "    # heater exchanger related\n",
    "    hx_related = [col for col in df2.columns if \"HX\" in col]\n",
    "    dfx = df2.loc[:, df2.columns.isin(hx_related)]\n",
    "    \n",
    "    # heater exchanger related\n",
    "    inner_related = [col for col in df2.columns if \"HeaterInner\" in col]\n",
    "    dfi = df2.loc[:, df2.columns.isin(inner_related)]\n",
    "    \n",
    "    # merge the three keywords related datasets together into `dfall`\n",
    "    dfall = pd.concat([dfb, dff, dfo, dfx, dfi], axis=1)\n",
    "    \n",
    "    mean_related = [col for col in dfall.columns if \"mean\" in col]\n",
    "    dfmean = dfall.loc[:, dfall.columns.isin(mean_related)]\n",
    "    \n",
    "    #Xbotmean = dfmean[dfmean.columns.drop(list(dfmean.filter(regex='11.FaceplateHeater_Temperature.mean')))]\n",
    "    Xmean = dfmean[dfmean.columns.drop(list(dfmean.filter(regex=pattern_interest)))]\n",
    "    ymean = dfmean.loc[:,[pattern_interest]]\n",
    "    \n",
    "    return Xmean, ymean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af038f",
   "metadata": {},
   "source": [
    "#### TCN module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8719558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0719b979",
   "metadata": {},
   "source": [
    "#### upper level of the TCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c579251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
    "        super(TCN, self).__init__()\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "        self.init_weights() # if the data needs to be weighted\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.linear.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.tcn(x)  # if multidimensional, input should have dimension (N, C, L)\n",
    "        o = self.linear(y1[:, :, -1])\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a91209",
   "metadata": {},
   "source": [
    "#### data generator for the adding problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45409e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def data_generator(percent_train, seq_length, path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        seq_length: Length of the adding problem data\n",
    "        starting_index: the index of where the sequence starts; starting from 0\n",
    "    \"\"\"\n",
    "    # Specifying the feature columns that we need for predictions\n",
    "    col1 = '11.BottomHeater_Temperature.mean'\n",
    "    col2 = '11.FaceplateHeater_Temperature.mean'\n",
    "    col3 = '11.HeaterOuterZone_Temperature.mean'\n",
    "    col = [col1, col2, col3]\n",
    "    \n",
    "    # Giving the path to the data set\n",
    "    csv = path\n",
    "    \n",
    "    # Data cleaning, getting the feature matrix and \n",
    "    X_bot, y_bot = data_cleaning(csv, col1)\n",
    "    \n",
    "    X_bot = torch.tensor(X_bot.to_numpy()).float()\n",
    "    y_bot = torch.tensor(y_bot.to_numpy()).float()\n",
    "    print(\"converted X_bot \", X_bot.shape, \"and y_bot \", y_bot.shape, \" to tensors\\n\")\n",
    "    \n",
    "    X_bot1 = torch.reshape(X_bot, [1, X_bot.shape[1], X_bot.shape[0]]) #[1,14,274]\n",
    "    y_bot1 = torch.reshape(y_bot, [1, y_bot.shape[0]]) #[1,274]\n",
    "\n",
    "    first_test_idx = int(round(percent_train * X_bot.shape[0]))\n",
    "    X_train = X_bot1[:, :, 0:first_test_idx]\n",
    "    X_test = X_bot1[:, :, first_test_idx:]\n",
    "    y_train = y_bot1[:, 0:first_test_idx]\n",
    "    y_test = y_bot1[:, first_test_idx:]\n",
    "    \n",
    "    X_train_final = torch.zeros([X_train.shape[2]-seq_length, X_train.shape[1], seq_length]) #[196, 14, 10] = [206-10, 14, 10]\n",
    "    y_train_final = torch.zeros([y_train.shape[1]-seq_length, 1]) #[196, 1] = [206-10, 1]\n",
    "    X_test_final = torch.zeros([X_test.shape[2]-seq_length, X_test.shape[1], seq_length]) #[58, 14, 10] = [68-10, 14, 10]\n",
    "    y_test_final = torch.zeros([y_test.shape[1]-seq_length, 1]) #[58,1] = [68-10, 1]\n",
    "    \n",
    "    for i in range(X_train.shape[2]-seq_length):\n",
    "        X_train_final[i, :, :] = X_train[: , : , i:i+seq_length]\n",
    "        y_train_final[i, :] = y_train[: , i+seq_length:i+seq_length+1]\n",
    "        \n",
    "    for i in range(X_test.shape[2]-seq_length):\n",
    "        X_test_final[i, :, :] = X_test[: , : , i:i+seq_length]\n",
    "        y_test_final[i, :] = y_test[: , i+seq_length:i+seq_length+1]\n",
    "#         print(\"at index i = \", i, \"y_test[1, \", i+seq_length, \"] = \",y_test[: , i+seq_length:i+seq_length+1])\n",
    "#         print(\"at index i = \", i, \"y_test_final[\",i, \", :] = \", y_test_final[i, :])\n",
    "\n",
    "    \n",
    "#     print(\"Y_train shape is set to: \", y_train_final.shape, \"; Y_train type is: \", type(y_train_final), \"\\n\")\n",
    "#     print(\"X_train shape is set to: \", X_train_final.shape, \"; X_train type is: \", type(X_train_final), \"\\n\")\n",
    "#     print(\"Y_test shape is set to: \", y_test_final.shape, \"; Y_test type is: \", type(y_test_final), \"\\n\")\n",
    "#     print(\"X_test shape is set to: \", X_test_final.shape, \"; X_test type is: \", type(X_test_final), \"\\n\")    \n",
    "    \n",
    "    return Variable(X_train_final), Variable(y_train_final), Variable(X_test_final), Variable(y_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d987e44",
   "metadata": {},
   "source": [
    "#### parameters needed for the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "715f4970",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 14 # # of input features\n",
    "n_classes = 1  #size of each output sample; output feature sizes of y_pred\n",
    "batch_size = 16 #batch size defaults to 32\n",
    "seq_length = 5 #sequence length; defaults to 400\n",
    "epochs = 20 #upper epoch limit; defaults to 10\n",
    "clip = -1 #args.clip; gradient clip, -1 means no clip (default: -1)\n",
    "log_interval = 10 #args.log_interval; 'report interval (default: 100')\n",
    "channel_sizes = [70]*2 #[args.nhid]*args.levels; number of hidden units per layer * # of levels\n",
    "kernel_size = 5 #args.ksize; kernel_size\n",
    "dropout =  0.0 #args.dropout; dropouts applied to each layer; defaults to 0.0\n",
    "model = TCN(input_channels, n_classes, channel_sizes, kernel_size=kernel_size, dropout=dropout)\n",
    "lr = 0.002725 # learning rate is defaulted to be 0.0040\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) #optimizer = getattr(optim, args.optim)(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa65da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted X_bot  torch.Size([274, 14]) and y_bot  torch.Size([274, 1])  to tensors\n",
      "\n",
      "torch.Size([159, 14, 5]) torch.Size([159, 1]) torch.Size([105, 14, 5]) torch.Size([105, 1])\n"
     ]
    }
   ],
   "source": [
    "percent = 0.6\n",
    "X_train, Y_train, X_test, Y_test = data_generator(percent, seq_length, r\"C:\\Users\\e177321\\Documents\\data\\Marathon_data.csv\")\n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e784c8c3",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce8873bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, input_channels=14):\n",
    "    global lr\n",
    "    \n",
    "    model.train()\n",
    "    batch_idx = 1\n",
    "    total_loss = 0\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        if i + batch_size > X_train.size(0):\n",
    "            x, y = X_train[i:], Y_train[i:]\n",
    "        else:\n",
    "            x, y = X_train[i:(i+batch_size)], Y_train[i:(i+batch_size)]\n",
    "            \n",
    "        #print(\"x.shape = \", x.shape, \"y.shape = \", y.shape)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = torch.nn.functional.mse_loss(output, y)\n",
    "        loss.backward()\n",
    "        if clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        batch_idx += 1\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            processed = min(i+batch_size, X_train.size(0))\n",
    "            print('Train Epoch: {:2d} [{:6d}/{:6d} ({:.0f}%)]\\tLearning rate: {:.4f}\\tLoss: {:.6f}'.format(\n",
    "                epoch, processed, X_train.size(0), 100.*processed/X_train.size(0), lr, cur_loss))\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e5073",
   "metadata": {},
   "source": [
    "#### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ae7c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test)\n",
    "        test_loss = torch.nn.functional.mse_loss(output, Y_test)\n",
    "        print('\\nTest set: Average loss: {:.6f}\\n'.format(test_loss.item()))\n",
    "        return Y_test, output, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f24f572d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:  1 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 5657.682904\n",
      "\n",
      "Test set: Average loss: 220.070129\n",
      "\n",
      "Train Epoch:  2 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 352.898589\n",
      "\n",
      "Test set: Average loss: 262.890015\n",
      "\n",
      "Train Epoch:  3 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 117.363282\n",
      "\n",
      "Test set: Average loss: 170.371658\n",
      "\n",
      "Train Epoch:  4 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 65.635758\n",
      "\n",
      "Test set: Average loss: 47.033920\n",
      "\n",
      "Train Epoch:  5 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 31.110577\n",
      "\n",
      "Test set: Average loss: 13.171392\n",
      "\n",
      "Train Epoch:  6 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 13.249965\n",
      "\n",
      "Test set: Average loss: 6.231647\n",
      "\n",
      "Train Epoch:  7 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 5.738759\n",
      "\n",
      "Test set: Average loss: 4.467470\n",
      "\n",
      "Train Epoch:  8 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 2.837977\n",
      "\n",
      "Test set: Average loss: 3.044619\n",
      "\n",
      "Train Epoch:  9 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 1.634189\n",
      "\n",
      "Test set: Average loss: 1.075724\n",
      "\n",
      "Train Epoch: 10 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 1.027337\n",
      "\n",
      "Test set: Average loss: 0.053570\n",
      "\n",
      "Train Epoch: 11 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 0.589755\n",
      "\n",
      "Test set: Average loss: 0.217360\n",
      "\n",
      "Train Epoch: 12 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 0.266769\n",
      "\n",
      "Test set: Average loss: 0.233632\n",
      "\n",
      "Train Epoch: 13 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 0.117729\n",
      "\n",
      "Test set: Average loss: 0.071579\n",
      "\n",
      "Train Epoch: 14 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 0.119678\n",
      "\n",
      "Test set: Average loss: 0.054417\n",
      "\n",
      "Train Epoch: 15 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 0.133221\n",
      "\n",
      "Test set: Average loss: 0.103249\n",
      "\n",
      "Train Epoch: 16 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 0.111372\n",
      "\n",
      "Test set: Average loss: 0.098743\n",
      "\n",
      "Train Epoch: 17 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 0.102619\n",
      "\n",
      "Test set: Average loss: 0.084503\n",
      "\n",
      "Train Epoch: 18 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 0.105609\n",
      "\n",
      "Test set: Average loss: 0.099234\n",
      "\n",
      "Train Epoch: 19 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 0.100269\n",
      "\n",
      "Test set: Average loss: 0.098754\n",
      "\n",
      "Train Epoch: 20 [   144/   159 (91%)]\tLearning rate: 0.0027\tLoss: 0.098913\n",
      "\n",
      "Test set: Average loss: 0.098895\n",
      "\n",
      "min loss found in ep  9 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = []\n",
    "lstoutput = []\n",
    "lstytest = []\n",
    "for ep in range(1, epochs+1):\n",
    "    train(ep)\n",
    "    Y_test, output, test_loss = evaluate()  \n",
    "    loss.append(test_loss.item())\n",
    "    lstoutput.append(output.tolist())\n",
    "    lstytest.append(Y_test.tolist())\n",
    "    \n",
    "minloss = min(loss)\n",
    "minidx = loss.index(minloss)\n",
    "\n",
    "Y_test = lstytest[minidx]\n",
    "output = lstoutput[minidx]\n",
    "    \n",
    "f, ax = plt.subplots()\n",
    "print(\"min loss found in ep \", minidx, \"\\n\")\n",
    "ax.scatter(Y_test, output,  color='black')\n",
    "ax.set_xlabel('Outputs from Marathon data')\n",
    "ax.set_ylabel('Outputs from predictions')\n",
    "#plt.xlim(159.7, 160.20)\n",
    "#plt.ylim(159.7, 160.20)\n",
    "#plt.gca().set_aspect('equal', adjustable='box')\n",
    "figname = \"tcn_opt_epoch_tune_opt_60percentdata\"\n",
    "ax.figure.savefig(figname, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f7005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
